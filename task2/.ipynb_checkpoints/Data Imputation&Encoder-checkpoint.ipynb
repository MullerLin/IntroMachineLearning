{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6efed29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613bfb0",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fd2a1",
   "metadata": {},
   "source": [
    "## Target def "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b26117",
   "metadata": {},
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)\n",
    "\n",
    "    # TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "\n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eebb6",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a981590",
   "metadata": {},
   "source": [
    " ##  load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d306d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a77de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2703f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    column_to_encode = 0\n",
    "    train_to_encode = train_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    test_to_encode = test_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(train_to_encode)\n",
    "    encoded_train_data = encoder.transform(train_to_encode)\n",
    "    encoded_train_arr = np.concatenate((train_arr[:, :column_to_encode],\n",
    "                            encoded_train_data.toarray(),\n",
    "                            train_arr[:, column_to_encode+1:]), axis=1)\n",
    "    \n",
    "    encoded_test_data = encoder.transform(test_to_encode)\n",
    "    encoded_test_arr = np.concatenate((test_arr[:, :column_to_encode],\n",
    "                            encoded_test_data.toarray(),\n",
    "                            test_arr[:, column_to_encode+1:]),axis=1)\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=15, weights = 'uniform')\n",
    "    imputed_train = imputer.fit_transform(encoded_train_arr)\n",
    "    imputed_test = imputer.fit_transform(encoded_test_arr)\n",
    "    \n",
    "    train_idx = [i for i in range(encoded_train_arr.shape[0]) if np.isnan(encoded_train_arr[i,5]) == False]\n",
    "    \n",
    "    imputed_train_refined = imputed_train[train_idx]\n",
    "    \n",
    "    X_train = np.delete(imputed_train_refined, 5, 1)\n",
    "    y_train = imputed_train_refined[:, 5]\n",
    "    X_test = imputed_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38391e04",
   "metadata": {},
   "source": [
    "###  referece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot_encoding(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    N = data.shape[0]\n",
    "    season_encoding_ndarry = np.zeros((N, 4))\n",
    "    seasons = ['spring', 'summer', 'autumn', 'winter']\n",
    "\n",
    "    for i in range(N):\n",
    "        season = [j for j in range(4) if seasons[j] == data['season'][i]]\n",
    "        assert(len(season) == 1)\n",
    "        season_encoding_ndarry[i][season[0]] = 1\n",
    "\n",
    "    season_encoding_df = pd.DataFrame(data=season_encoding_ndarry, columns=seasons)\n",
    "    price_df = data.drop(['season'],axis=1)\n",
    "    encoded_data_df = pd.concat([season_encoding_df, price_df], axis=1)\n",
    "    return encoded_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc63215",
   "metadata": {},
   "outputs": [],
   "source": [
    "    encoded_train_df = oneHot_encoding(train_df)\n",
    "    encoded_test_df = oneHot_encoding(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_idx = [i for i in range(encoded_train_df.shape[0]) if np.isnan(encoded_train_df['price_CHF'][i]) == False]\n",
    "    print('length: ', len(train_idx))\n",
    "\n",
    "    X_train_raw = np.delete(imputed_train, 5, 1)\n",
    "    y_train_raw = imputed_train[:, 5]\n",
    "\n",
    "    # dt = pd.DataFrame(y_train_raw, columns=['label'])\n",
    "    # dt.to_csv('y_train_raw.csv', index=False)\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = X_train_raw.take(train_idx, 0)\n",
    "    y_train = y_train_raw.take(train_idx, 0)\n",
    "    X_test = imputed_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f07882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d343aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)\n",
    "\n",
    "    # TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    column_to_encode = 0\n",
    "    train_to_encode = train_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    test_to_encode = test_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(train_to_encode)\n",
    "    encoded_train_data = encoder.transform(train_to_encode)\n",
    "    encoded_train_arr = np.concatenate((train_arr[:, :column_to_encode],\n",
    "                            encoded_train_data.toarray(),\n",
    "                            train_arr[:, column_to_encode+1:]), axis=1)\n",
    "    \n",
    "    encoded_test_data = encoder.transform(test_to_encode)\n",
    "    encoded_test_arr = np.concatenate((test_arr[:, :column_to_encode],\n",
    "                            encoded_test_data.toarray(),\n",
    "                            test_arr[:, column_to_encode+1:]),axis=1)\n",
    "    \n",
    "    # KNN Imputer\n",
    "    imputer = KNNImputer(n_neighbors=15, weights = 'uniform')\n",
    "    imputed_train = imputer.fit_transform(encoded_train_arr)\n",
    "    imputed_test = imputer.fit_transform(encoded_test_arr)\n",
    "    \n",
    "    train_idx = [i for i in range(encoded_train_arr.shape[0]) if np.isnan(encoded_train_arr[i,5]) == False]\n",
    "    \n",
    "    imputed_train_refined = imputed_train[train_idx]\n",
    "    \n",
    "    X_train = np.delete(imputed_train_refined, 5, 1)\n",
    "    y_train = imputed_train_refined[:, 5]\n",
    "    \n",
    "    X_test = imputed_test\n",
    "    \n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e320d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAIML]",
   "language": "python",
   "name": "conda-env-PAIML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
