{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b05427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116975f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d2318",
   "metadata": {},
   "source": [
    "# Data Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2881924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)\n",
    "\n",
    "    # TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    column_to_encode = 0\n",
    "    train_to_encode = train_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    test_to_encode = test_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(train_to_encode)\n",
    "    encoded_train_data = encoder.transform(train_to_encode)\n",
    "    encoded_train_arr = np.concatenate((train_arr[:, :column_to_encode],\n",
    "                            encoded_train_data.toarray(),\n",
    "                            train_arr[:, column_to_encode+1:]), axis=1)\n",
    "    \n",
    "    encoded_test_data = encoder.transform(test_to_encode)\n",
    "    encoded_test_arr = np.concatenate((test_arr[:, :column_to_encode],\n",
    "                            encoded_test_data.toarray(),\n",
    "                            test_arr[:, column_to_encode+1:]),axis=1)\n",
    "    \n",
    "    # KNN Imputer\n",
    "    imputer = KNNImputer(n_neighbors=5, weights = 'distance')\n",
    "    imputed_train = imputer.fit_transform(encoded_train_arr)\n",
    "    imputed_test = imputer.fit_transform(encoded_test_arr)\n",
    "    \n",
    "    # delete the price of electric of swi\n",
    "    train_idx = [i for i in range(encoded_train_arr.shape[0]) if np.isnan(encoded_train_arr[i,5]) == False] \n",
    "    imputed_train_refined = imputed_train[train_idx]\n",
    "    \n",
    "    X_train = np.delete(imputed_train_refined, 5, 1)\n",
    "    y_train = imputed_train_refined[:, 5]\n",
    "    \n",
    "    X_test = imputed_test\n",
    "    \n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c86d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Shape: (900, 11)\n",
      "   season  price_AUS  price_CHF  price_CZE  price_GER  price_ESP  price_FRA  \\\n",
      "0  spring        NaN   9.644028  -1.686248  -1.748076  -3.666005        NaN   \n",
      "1  summer        NaN   7.246061  -2.132377  -2.054363  -3.295697  -4.104759   \n",
      "\n",
      "   price_UK  price_ITA  price_POL  price_SVK  \n",
      "0 -1.822720  -3.931031        NaN  -3.238197  \n",
      "1 -1.826021        NaN        NaN  -3.212894  \n",
      "\n",
      "\n",
      "Test data:\n",
      "(100, 10)\n",
      "   season  price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0  spring        NaN   0.472985   0.707957        NaN  -1.136441 -0.596703   \n",
      "1  summer  -1.184837   0.358019        NaN  -3.199028  -1.069695       NaN   \n",
      "\n",
      "   price_ITA  price_POL  price_SVK  \n",
      "0        NaN   3.298693   1.921886  \n",
      "1  -1.420091   3.238307        NaN  \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = data_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc261d2",
   "metadata": {},
   "source": [
    "# Model Test and Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c178f",
   "metadata": {},
   "source": [
    "## Kernel Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f1e28",
   "metadata": {},
   "source": [
    "### Matern Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_range = np.logspace(-5, 1, 100, base=10)\n",
    "nu_range = np.logspace(-5, 1, 100, base=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [  (0.05, 0.5), (0.05, 1.5), (0.05, 2.5),\n",
    "                (0.1, 0.5), (0.1, 1.5), (0.1, 2.5),\n",
    "                (1, 0.5), (1, 1.5), (1, 2.5)]\n",
    "for i in range (len(ls_range)):\n",
    "    for j in range (len(nu_range)):\n",
    "        params.append((ls_range[i], nu_range[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb3739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matern_para_select(X, y, n_folds):\n",
    "    print(\"————Matern————\")\n",
    "    ls_range = np.logspace(-2, 1, 10, base=10)\n",
    "    nu_range = np.logspace(-2, 1, 10, base=10)\n",
    "    params = [  (0.05, 0.5), (0.05, 1.5), (0.05, 2.5),\n",
    "                (0.1, 0.5), (0.1, 1.5), (0.1, 2.5),\n",
    "                (1, 0.5), (1, 1.5), (1, 2.5)]\n",
    "#     for i in range (len(ls_range)):\n",
    "#         for j in range (len(nu_range)):\n",
    "#             params.append((ls_range[i], nu_range[j]))\n",
    "    R2score_mat = np.zeros((n_folds, len(params)))\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state= 14)\n",
    "    for fold_idx, (train, test) in enumerate(kf.split(X)):\n",
    "        X_train, X_val, y_train, y_val = X[train], X[test], y[train], y[test]\n",
    "        for idx, (ls, nu) in enumerate(params):\n",
    "            gpr = GaussianProcessRegressor(kernel= Matern(length_scale=ls, nu=nu))\n",
    "            gpr.fit(X_train, y_train)\n",
    "            y_val_pred = gpr.predict(X_val)\n",
    "            R2score_mat[fold_idx][idx] = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    avg_R2score = np.mean(R2score_mat, axis=0)\n",
    "    print(\"Best Param: \", params[np.argmax([avg_R2score])], \" Score: \", avg_R2score[np.argmax([avg_R2score])])\n",
    "    # print(avg_R2score)\n",
    "    print(\"______________end_____________\")\n",
    "    return avg_R2score, params[np.argmax([avg_R2score])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efb17040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————Matern————\n",
      "Best Param:  (1, 0.5)  Score:  0.9831471878381295\n",
      "______________end_____________\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "avg_R2score_M, best_para_M = Matern_para_select(X_train, y_train, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ec7bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr = GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=0.5))\n",
    "gpr.fit(X_train, y_train)\n",
    "y_pred = gpr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19635ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in the required format\n",
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584c5f6",
   "metadata": {},
   "source": [
    "### Rational Quadratic Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "806e18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RationalQuardratic_para_select(X, y, n_folds):\n",
    "    print(\"————Rational Quadratic————\")\n",
    "    ls_range = np.logspace(-2, 0.5, 10, base=10)\n",
    "    alp_range = np.logspace(-2, 0.5, 10, base=10)\n",
    "    params = [  (0.1, 0.1), (0.1, 1),\n",
    "                (1, 0.1), (1, 1)]\n",
    "#     for i in range(len(ls_range)):\n",
    "#         for j in range(len(alp_range)):\n",
    "#             params.append((ls_range[i], alp_range[j]))\n",
    "    R2score_mat = np.zeros((n_folds, len(params)))    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state= 14)\n",
    "    for fold_idx, (train, test) in enumerate(kf.split(X)):\n",
    "        X_train, X_val, y_train, y_val = X[train], X[test], y[train], y[test]\n",
    "        for idx, (ls, alp) in enumerate(params):\n",
    "            gpr = GaussianProcessRegressor(kernel = RationalQuadratic(length_scale=ls, alpha=alp))\n",
    "            gpr.fit(X_train, y_train)\n",
    "            y_val_pred = gpr.predict(X_val)\n",
    "            R2score_mat[fold_idx][idx] = r2_score(y_val, y_val_pred)\n",
    "            \n",
    "    avg_R2score = np.mean(R2score_mat, axis=0)\n",
    "    print(\"Best Param: \", params[np.argmax([avg_R2score])], \" Score: \", avg_R2score[np.argmax([avg_R2score])])\n",
    "    # print(avg_R2score)\n",
    "    print(\"______________end_____________\")\n",
    "    return avg_R2score, params[np.argmax([avg_R2score])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffaa208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————Rational Quadratic————\n",
      "Best Param:  (0.1, 1)  Score:  0.9806467592204626\n",
      "______________end_____________\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "avg_R2score, best_para_RQ = RationalQuardratic_para_select(X_train, y_train, n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1503a",
   "metadata": {},
   "source": [
    "### Mix Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea5cb2",
   "metadata": {},
   "source": [
    "###  Rational Quadratic + Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed3306a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RQM_sup_para_select(X, y, n_folds):\n",
    "    print(\"————Rational Quadratic + Matern————\")\n",
    "    RQ_params = [  (0.1, 0.1), (0.1, 1),\n",
    "                (1, 0.1), (1, 1)]\n",
    "    M_params = [  (0.05, 0.5), (0.05, 1.5), (0.05, 2.5),\n",
    "                (0.1, 0.5), (0.1, 1.5), (0.1, 2.5),\n",
    "                (1, 0.5), (1, 1.5), (1, 2.5)]\n",
    "    params = []\n",
    "    for i in range(len(RQ_params)):\n",
    "        for j in range(len(M_params)):\n",
    "            params.append((RQ_params[i], M_params[j]))\n",
    "    R2score_mat = np.zeros((n_folds, len(params)))    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state= 14)\n",
    "    pbar = tqdm(total=len(params)*n_folds)\n",
    "    for fold_idx, (train, test) in enumerate(kf.split(X)):\n",
    "        X_train, X_val, y_train, y_val = X[train], X[test], y[train], y[test]\n",
    "        for idx, (RQ, M) in enumerate(params):\n",
    "            kernel = RationalQuadratic(length_scale=RQ[0], alpha=RQ[1]) + Matern(length_scale=M[0], nu=M[1])\n",
    "            gpr = GaussianProcessRegressor(kernel = kernel, n_restarts_optimizer=9)\n",
    "            gpr.fit(X_train, y_train)\n",
    "            y_val_pred = gpr.predict(X_val)\n",
    "            R2score_mat[fold_idx][idx] = r2_score(y_val, y_val_pred)\n",
    "            pbar.update()\n",
    "    pbar.close()            \n",
    "    avg_R2score = np.mean(R2score_mat, axis=0)\n",
    "    print(\"Best Param: \", params[np.argmax([avg_R2score])], \" Score: \", avg_R2score[np.argmax([avg_R2score])])\n",
    "    # print(avg_R2score)\n",
    "    print(\"______________end_____________\")\n",
    "    return avg_R2score, params[np.argmax([avg_R2score])]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62dfaa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————Rational Quadratic + Matern————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/mullin/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param:  ((0.1, 1), (1, 2.5))  Score:  0.9840200842253258\n",
      "______________end_____________\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "avg_R2score_sup, best_para_sup = RQM_sup_para_select(X_train, y_train, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e34f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel= RationalQuadratic(length_scale=0.1, alpha=1) + Matern(length_scale=1, nu=2.5)\n",
    "gpr = GaussianProcessRegressor(kernel = kernel)\n",
    "gpr.fit(X_train, y_train)\n",
    "y_pred = gpr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aede01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in the required format\n",
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503f42",
   "metadata": {},
   "source": [
    "### Rational Quadratic * Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f771830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RQM_mul_para_select(X, y, n_folds):\n",
    "    print(\"————Rational Quadratic * Matern————\")\n",
    "    RQ_params = [  (0.1, 0.1), (0.1, 0.5),(0.1, 1), \n",
    "                 (0.5, 0.1), (0.5, 0.5), (0.5, 1),\n",
    "                (1, 0.1), (1, 0.5), (1, 1)]\n",
    "    M_params = [ (0.05, 0.2), (0.05, 0.4), (0.05, 0.5), (0.05, 1.5), (0.05, 2.5),\n",
    "                (0.1, 0.2), (0.1, 0.4),(0.1, 0.5), (0.1, 1.5), (0.1, 2.5),\n",
    "                (0.25, 0.2), (0.25, 0.4),(0.25, 0.5), (0.25, 1.5), (0.25, 2.5),\n",
    "                (0.4, 0.2), (0.4, 0.4),(0.4, 0.5), (0.4, 1.5), (0.4, 2.5),\n",
    "                (0.6, 0.2), (0.6, 0.4),(0.6, 0.5), (0.6, 1.5), (0.6, 2.5),\n",
    "                (1, 0.2), (1, 0.4),(1, 0.5), (1, 1.5), (1, 2.5)]\n",
    "\n",
    "    params = []\n",
    "    for i in range(len(RQ_params)):\n",
    "        for j in range(len(M_params)):\n",
    "            params.append((RQ_params[i], M_params[j]))\n",
    "    R2score_mat = np.zeros((n_folds, len(params)))    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state= 14)\n",
    "    pbar = tqdm(total=len(params)*n_folds)\n",
    "    for fold_idx, (train, test) in enumerate(kf.split(X)):\n",
    "        X_train, X_val, y_train, y_val = X[train], X[test], y[train], y[test]\n",
    "        for idx, (RQ, M) in enumerate(params):\n",
    "            kernel = RationalQuadratic(length_scale=RQ[0], alpha=RQ[1]) * Matern(length_scale=M[0], nu=M[1])\n",
    "            gpr = GaussianProcessRegressor(kernel = kernel, n_restarts_optimizer=9)\n",
    "            gpr.fit(X_train, y_train)\n",
    "            y_val_pred = gpr.predict(X_val)\n",
    "            R2score_mat[fold_idx][idx] = r2_score(y_val, y_val_pred)\n",
    "            pbar.update()\n",
    "    pbar.close()            \n",
    "    avg_R2score = np.mean(R2score_mat, axis=0)\n",
    "    print(\"Best Param: \", params[np.argmax([avg_R2score])], \" Score: \", avg_R2score[np.argmax([avg_R2score])])\n",
    "    # print(avg_R2score)\n",
    "    print(\"______________end_____________\")\n",
    "    return avg_R2score, params[np.argmax([avg_R2score])]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8181c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————Rational Quadratic * Matern————\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m avg_R2score_mul, best_para_mul \u001b[38;5;241m=\u001b[39m \u001b[43mRQM_mul_para_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 23\u001b[0m, in \u001b[0;36mRQM_mul_para_select\u001b[0;34m(X, y, n_folds)\u001b[0m\n\u001b[1;32m     21\u001b[0m kernel \u001b[38;5;241m=\u001b[39m RationalQuadratic(length_scale\u001b[38;5;241m=\u001b[39mRQ[\u001b[38;5;241m0\u001b[39m], alpha\u001b[38;5;241m=\u001b[39mRQ[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m Matern(length_scale\u001b[38;5;241m=\u001b[39mM[\u001b[38;5;241m0\u001b[39m], nu\u001b[38;5;241m=\u001b[39mM[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     22\u001b[0m gpr \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor(kernel \u001b[38;5;241m=\u001b[39m kernel, n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mgpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m gpr\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     25\u001b[0m R2score_mat[fold_idx][idx] \u001b[38;5;241m=\u001b[39m r2_score(y_val, y_val_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:304\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[1;32m    302\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    303\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 304\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[1;32m    308\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:622\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 622\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    630\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:276\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 276\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:546\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    543\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 546\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:941\u001b[0m, in \u001b[0;36mProduct.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m    940\u001b[0m     K1, K1_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 941\u001b[0m     K2, K2_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m*\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack(\n\u001b[1;32m    943\u001b[0m         (K1_gradient \u001b[38;5;241m*\u001b[39m K2[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis], K2_gradient \u001b[38;5;241m*\u001b[39m K1[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis])\n\u001b[1;32m    944\u001b[0m     )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:1756\u001b[0m, in \u001b[0;36mMatern.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(theta):  \u001b[38;5;66;03m# helper function\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone_with_theta(theta)(X, Y)\n\u001b[0;32m-> 1756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K, \u001b[43m_approx_fprime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manisotropic:\n\u001b[1;32m   1759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K, K_gradient[:, :]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:2219\u001b[0m, in \u001b[0;36m_approx_fprime\u001b[0;34m(xk, f, epsilon, args)\u001b[0m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_approx_fprime\u001b[39m(xk, f, epsilon, args\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m-> 2219\u001b[0m     f0 \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2220\u001b[0m     grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((f0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], f0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mlen\u001b[39m(xk)), \u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m   2221\u001b[0m     ei \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(xk),), \u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:1754\u001b[0m, in \u001b[0;36mMatern.__call__.<locals>.f\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(theta):  \u001b[38;5;66;03m# helper function\u001b[39;00m\n\u001b[0;32m-> 1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_with_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/PAIML/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:1713\u001b[0m, in \u001b[0;36mMatern.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     K\u001b[38;5;241m.\u001b[39mfill((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu)) \u001b[38;5;241m/\u001b[39m gamma(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu))\n\u001b[1;32m   1712\u001b[0m     K \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu\n\u001b[0;32m-> 1713\u001b[0m     K \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mkv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# convert from upper-triangular matrix to square matrix\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m     K \u001b[38;5;241m=\u001b[39m squareform(K)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "avg_R2score_mul, best_para_mul = RQM_mul_para_select(X_train, y_train, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96bf9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel= RationalQuadratic(length_scale=0.1, alpha=1) * Matern(length_scale=1, nu=2.5)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel)\n",
    "gpr.fit(X_train, y_train)\n",
    "y_pred = gpr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d28d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in the required format\n",
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75d44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAIML]",
   "language": "python",
   "name": "conda-env-PAIML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
