{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6efed29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613bfb0",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fd2a1",
   "metadata": {},
   "source": [
    "## Target def "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b26117",
   "metadata": {},
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)\n",
    "\n",
    "    # TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "\n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eebb6",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbdc99",
   "metadata": {},
   "source": [
    " ##  load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81d306d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Shape: (900, 11)\n",
      "   season  price_AUS  price_CHF  price_CZE  price_GER  price_ESP  price_FRA  \\\n",
      "0  spring        NaN   9.644028  -1.686248  -1.748076  -3.666005        NaN   \n",
      "1  summer        NaN   7.246061  -2.132377  -2.054363  -3.295697  -4.104759   \n",
      "\n",
      "   price_UK  price_ITA  price_POL  price_SVK  \n",
      "0 -1.822720  -3.931031        NaN  -3.238197  \n",
      "1 -1.826021        NaN        NaN  -3.212894  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24a77de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n",
      "(100, 10)\n",
      "   season  price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0  spring        NaN   0.472985   0.707957        NaN  -1.136441 -0.596703   \n",
      "1  summer  -1.184837   0.358019        NaN  -3.199028  -1.069695       NaN   \n",
      "\n",
      "   price_ITA  price_POL  price_SVK  \n",
      "0        NaN   3.298693   1.921886  \n",
      "1  -1.420091   3.238307        NaN  \n"
     ]
    }
   ],
   "source": [
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2703f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9a120",
   "metadata": {},
   "source": [
    "### Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    column_to_encode = 0\n",
    "    train_to_encode = train_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    test_to_encode = test_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(train_to_encode)\n",
    "    encoded_train_data = encoder.transform(train_to_encode)\n",
    "    encoded_train_arr = np.concatenate((train_arr[:, :column_to_encode],\n",
    "                            encoded_train_data.toarray(),\n",
    "                            train_arr[:, column_to_encode+1:]), axis=1)\n",
    "    \n",
    "    encoded_test_data = encoder.transform(test_to_encode)\n",
    "    encoded_test_arr = np.concatenate((test_arr[:, :column_to_encode],\n",
    "                            encoded_test_data.toarray(),\n",
    "                            test_arr[:, column_to_encode+1:]),axis=1)\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=15, weights = 'uniform')\n",
    "    imputed_train = imputer.fit_transform(encoded_train_arr)\n",
    "    imputed_test = imputer.fit_transform(encoded_test_arr)\n",
    "    \n",
    "    train_idx = [i for i in range(encoded_train_arr.shape[0]) if np.isnan(encoded_train_arr[i,5]) == False]\n",
    "    \n",
    "    imputed_train_refined = imputed_train[train_idx]\n",
    "    \n",
    "    X_train = np.delete(imputed_train_refined, 5, 1)\n",
    "    y_train = imputed_train_refined[:, 5]\n",
    "    X_test = imputed_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750c8b3",
   "metadata": {},
   "source": [
    "###  referece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "654fa2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot_encoding(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    N = data.shape[0]\n",
    "    season_encoding_ndarry = np.zeros((N, 4))\n",
    "    seasons = ['spring', 'summer', 'autumn', 'winter']\n",
    "\n",
    "    for i in range(N):\n",
    "        season = [j for j in range(4) if seasons[j] == data['season'][i]]\n",
    "        assert(len(season) == 1)\n",
    "        season_encoding_ndarry[i][season[0]] = 1\n",
    "\n",
    "    season_encoding_df = pd.DataFrame(data=season_encoding_ndarry, columns=seasons)\n",
    "    price_df = data.drop(['season'],axis=1)\n",
    "    encoded_data_df = pd.concat([season_encoding_df, price_df], axis=1)\n",
    "    return encoded_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76a03c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "    encoded_train_df = oneHot_encoding(train_df)\n",
    "    encoded_test_df = oneHot_encoding(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a05874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  631\n"
     ]
    }
   ],
   "source": [
    "    train_idx = [i for i in range(encoded_train_df.shape[0]) if np.isnan(encoded_train_df['price_CHF'][i]) == False]\n",
    "    print('length: ', len(train_idx))\n",
    "\n",
    "    X_train_raw = np.delete(imputed_train, 5, 1)\n",
    "    y_train_raw = imputed_train[:, 5]\n",
    "\n",
    "    # dt = pd.DataFrame(y_train_raw, columns=['label'])\n",
    "    # dt.to_csv('y_train_raw.csv', index=False)\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train_ref = X_train_raw.take(train_idx, 0)\n",
    "    y_train_ref = y_train_raw.take(train_idx, 0)\n",
    "    X_test_ref = imputed_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e93791",
   "metadata": {},
   "source": [
    "### def implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d343aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))\n",
    "\n",
    "    # Dummy initialization of the X_train, X_test and y_train   \n",
    "    X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "    y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    X_test = np.zeros_like(test_df)\n",
    "\n",
    "    # TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    train_arr = np.array(train_df)\n",
    "    test_arr = np.array(test_df)\n",
    "    \n",
    "    # one hot encoder\n",
    "    column_to_encode = 0\n",
    "    train_to_encode = train_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    test_to_encode = test_arr[:, column_to_encode].reshape(-1, 1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(train_to_encode)\n",
    "    encoded_train_data = encoder.transform(train_to_encode)\n",
    "    encoded_train_arr = np.concatenate((train_arr[:, :column_to_encode],\n",
    "                            encoded_train_data.toarray(),\n",
    "                            train_arr[:, column_to_encode+1:]), axis=1)\n",
    "    \n",
    "    encoded_test_data = encoder.transform(test_to_encode)\n",
    "    encoded_test_arr = np.concatenate((test_arr[:, :column_to_encode],\n",
    "                            encoded_test_data.toarray(),\n",
    "                            test_arr[:, column_to_encode+1:]),axis=1)\n",
    "    \n",
    "    # KNN Imputer\n",
    "    imputer = KNNImputer(n_neighbors=15, weights = 'uniform')\n",
    "    imputed_train = imputer.fit_transform(encoded_train_arr)\n",
    "    imputed_test = imputer.fit_transform(encoded_test_arr)\n",
    "    \n",
    "    # delete the price of electric of swi\n",
    "    train_idx = [i for i in range(encoded_train_arr.shape[0]) if np.isnan(encoded_train_arr[i,5]) == False] \n",
    "    imputed_train_refined = imputed_train[train_idx]\n",
    "    \n",
    "    X_train = np.delete(imputed_train_refined, 5, 1)\n",
    "    y_train = imputed_train_refined[:, 5]\n",
    "    \n",
    "    X_test = imputed_test\n",
    "    \n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815bfbe5",
   "metadata": {},
   "source": [
    "###  Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "356530e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Shape: (900, 11)\n",
      "   season  price_AUS  price_CHF  price_CZE  price_GER  price_ESP  price_FRA  \\\n",
      "0  spring        NaN   9.644028  -1.686248  -1.748076  -3.666005        NaN   \n",
      "1  summer        NaN   7.246061  -2.132377  -2.054363  -3.295697  -4.104759   \n",
      "\n",
      "   price_UK  price_ITA  price_POL  price_SVK  \n",
      "0 -1.822720  -3.931031        NaN  -3.238197  \n",
      "1 -1.826021        NaN        NaN  -3.212894  \n",
      "\n",
      "\n",
      "Test data:\n",
      "(100, 10)\n",
      "   season  price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0  spring        NaN   0.472985   0.707957        NaN  -1.136441 -0.596703   \n",
      "1  summer  -1.184837   0.358019        NaN  -3.199028  -1.069695       NaN   \n",
      "\n",
      "   price_ITA  price_POL  price_SVK  \n",
      "0        NaN   3.298693   1.921886  \n",
      "1  -1.420091   3.238307        NaN  \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = data_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "228dadcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      " True \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "print((X_train == X_train_ref).all(),'\\n',\n",
    "     (y_train == y_train_ref).all(), '\\n',\n",
    "     (X_test == X_test_ref).all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAIML]",
   "language": "python",
   "name": "conda-env-PAIML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
