{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7dab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20598c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1   x2     x3   x4     x5     x6     x7      x8    x9    x10   x11  \\\n",
      "0   0.06724  0.0   3.24  0.0  0.460  6.333   17.2  5.2146   4.0  430.0  16.9   \n",
      "1   9.23230  0.0  18.10  0.0  0.631  6.216  100.0  1.1691  24.0  666.0  20.2   \n",
      "2   0.11425  0.0  13.89  1.0  0.550  6.373   92.4  3.3633   5.0  276.0  16.4   \n",
      "3  24.80170  0.0  18.10  0.0  0.693  5.349   96.0  1.7028  24.0  666.0  20.2   \n",
      "4   0.05646  0.0  12.83  0.0  0.437  6.232   53.7  5.0141   5.0  398.0  18.7   \n",
      "\n",
      "      x12    x13  \n",
      "0  375.21   7.34  \n",
      "1  366.15   9.53  \n",
      "2  393.74  10.50  \n",
      "3  396.90  19.77  \n",
      "4  386.40  12.34  \n"
     ]
    }
   ],
   "source": [
    "    # Data loading\n",
    "    data = pd.read_csv(\"train.csv\")\n",
    "    y = data[\"y\"].to_numpy()\n",
    "    data = data.drop(columns=\"y\")\n",
    "    # print a few data samples\n",
    "    print(data.head())\n",
    "\n",
    "    X = data.to_numpy()\n",
    "    # The function calculating the average RMSE\n",
    "    lambdas = [0.1, 1, 10, 100, 200]\n",
    "    n_folds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef775d1",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14c77fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=10, fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=10, fit_intercept=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=10, fit_intercept=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 10\n",
    "ridge_reg = Ridge(alpha=lam, fit_intercept=False)\n",
    "ridge_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d62a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = full_ridge_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1589fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, lam):\n",
    "    \"\"\"\n",
    "    This function receives training data points, then fits the ridge regression on this data\n",
    "    with regularization hyperparameter lambda. The weights w of the fitted ridge regression\n",
    "    are returned. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: matrix of floats, dim = (135,13), inputs with 13 features\n",
    "    y: array of floats, dim = (135,), input labels)\n",
    "    lam: float. lambda parameter, used in regularization term\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    w: array of floats: dim = (13,), optimal parameters of ridge regression\n",
    "    \"\"\"\n",
    "    w = np.zeros((13,))\n",
    "    # TODO: Enter your code here\n",
    "    ridge_reg = Ridge(alpha=lam, fit_intercept=False)\n",
    "    ridge_reg.fit(X, y)\n",
    "    w = full_ridge_reg.coef_\n",
    "    assert w.shape == (13,)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b3d28",
   "metadata": {},
   "source": [
    "## RMSE calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feb78ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = X @ weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da26c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "945fd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(np.sum(y - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "462788a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.11415404528594"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1385d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(w, X, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of \n",
    "    predicting y from X using a linear model with weights w. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w: array of floats: dim = (13,), optimal parameters of ridge regression \n",
    "    X: matrix of floats, dim = (15,13), inputs with 13 features\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "    RMSE = 0\n",
    "    # TODO: Enter your code here\n",
    "    y_pred = X @ w\n",
    "    RMSE = sqrt(np.sum(y - y_pred) ** 2)\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ac60c",
   "metadata": {},
   "source": [
    "##  Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701db8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7208dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "1\n",
      "10\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for lam in lambdas:\n",
    "    print(lam)\n",
    "    kf = KFold(n_splits = n_folds)\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "        weight = fit(X[train_index], y[train_index], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_LR_RMSE(X, y, lambdas, n_folds):\n",
    "    \"\"\"\n",
    "    Main cross-validation loop, implementing 10-fold CV. In every iteration (for every train-test split), the RMSE for every lambda is calculated, \n",
    "    and then averaged over iterations.\n",
    "    \n",
    "    Parameters\n",
    "    ---------- \n",
    "    X: matrix of floats, dim = (150, 13), inputs with 13 features\n",
    "    y: array of floats, dim = (150, ), input labels\n",
    "    lambdas: list of floats, len = 5, values of lambda for which ridge regression is fitted and RMSE estimated\n",
    "    n_folds: int, number of folds (pieces in which we split the dataset), parameter K in KFold CV\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    avg_RMSE: array of floats: dim = (5,), average RMSE value for every lambda\n",
    "    \"\"\"\n",
    "    RMSE_mat = np.zeros((n_folds, len(lambdas)))\n",
    "\n",
    "    # TODO: Enter your code here. Hint: Use functions 'fit' and 'calculate_RMSE' with training and test data\n",
    "    # and fill all entries in the matrix 'RMSE_mat'\n",
    "\n",
    "    avg_RMSE = np.mean(RMSE_mat, axis=0)\n",
    "    assert avg_RMSE.shape == (5,)\n",
    "    return avg_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ff4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAIML]",
   "language": "python",
   "name": "conda-env-PAIML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
